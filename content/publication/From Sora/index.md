---
title: "From Sora What We Can See: A Survey of Text-to-Video Generation"
authors:
- Rui Sun
- Yumin Zhang
-  Tejal Shah
-  Jiaohao Sun
-   Shuoying Zhang
-   Wenqi Li
-  Haoran Duan
- Bo Wei
- Rajiv Ranjan
date: ""
doi: "10.13140/RG.2.2.30257.19045"

# Schedule page publish date (NOT publication's date).
publishDate: "2024-03-28T00:00:00Z"

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article"]

# Publication name and optional abbreviated publication name.
publication: ""
publication_short: ""

abstract: With impressive achievements made, artificial intelligence is on the path forward to artificial general intelligence. Sora,
developed by OpenAI, which is capable of minute-level world-simulative abilities can be considered as a milestone on this developmental
path. However, despite its notable successes, Sora still encounters various obstacles that need to be resolved. In this survey, we embark
from the perspective of disassembling Sora in text-to-video generation, and conducting a comprehensive review of literature, trying to
answer the question, From Sora What We Can See. Specifically, after basic preliminaries regarding the general algorithms are introduced,
the literature is categorized from three mutually perpendicular dimensionsï¼š evolutionary generators, excellent pursuit, and realistic
panorama. Subsequently, the widely used datasets and metrics are organized in detail. Last but more importantly, we identify several
challenges and open problems in this domain and propose potential future directions for research and development. A comprehensive list
of text-to-video generation studies in this survey is available at https://github.com/soraw-ai/Awesome-Text-to-Video-Generation

# Summary. An optional shortened abstract.
# summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.

tags:
- Source Themes
featured: false

links:
url_pdf: https://www.researchgate.net/profile/Rui-Sun-87/publication/378942793_From_Sora_What_We_Can_See_A_Survey_of_Text-to-Video_Generation/links/65f2d8cac05fd2688010abca/From-Sora-What-We-Can-See-A-Survey-of-Text-to-Video-Generation.pdf
# - name: Custom Link
#   url: http://example.org

url_code: 'https://github.com/soraw-ai/Awesome-Text-to-Video-Generation'
# url_dataset: '#'
# url_poster: '#'
# url_project: ''
# url_slides: ''
# url_source: '#'
# url_video: '#'

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/s9CC2SKySJM)'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
# projects:
# - internal-project

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

<!-- {{% callout note %}}
Create your slides in Markdown - click the *Slides* button to check out the example.
{{% /callout %}} -->

**cite** 
```

```


<!-- Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). -->
