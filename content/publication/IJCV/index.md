---
title: "When Multi-Focus Image Fusion Networks Meet Traditional Edge-Preservation Technology"
authors:
- Wang Zeyu
- Li Xiongfei
- Zhao Libo
- Duan Haoran 
- Wang Shidong 
- Liu Hao
- Zhang Xiaoli
date: "2023-07-09T00:00:00Z"
doi: "https://doi.org/10.1007/s11263-023-01806-w"

# Schedule page publish date (NOT publication's date).
publishDate: "2024-03-28T00:00:00Z"

# Publication type.
# Accepts a single type but formatted as a YAML list (for Hugo requirements).
# Enter a publication type from the CSL standard.
publication_types: ["article"]

# Publication name and optional abbreviated publication name.
publication: "International Journal of Computer Vision"
publication_short: "IJCV"

abstract: Generating the decision map with accurate boundaries is the key to fusing multi-focus images. In this paper, we introduce edge-preservation (EP) techniques into neural networks to improve the quality of decision maps, supported by an interesting phenomenon we found the maps generated by traditional EP techniques are similar to the feature maps in the trained network with excellent performance. Based on the manifold theory in the field of edge-preservation, we propose a novel edge-aware layer derived from isometric domain transformation and a recursive filter, which effectively eliminates burrs and pseudo-edges in the decision map by highlighting the edge discrepancy between the focused and defocused regions. This edge-aware layer is incorporated to a Siamese-style encoder and a decoder to form a complete segmentation architecture, termed Y-Net, which can contrastively learn and capture the feature differences of the sourced images with a relatively small number of training data (i.e., 10,000 image pairs). In addition, a new strategy based on randomization is devised to generate masks and simulate multi-focus images with natural images, which alleviates the absence of ground-truth and the lack of training sets in multi-focus image fusion (MFIF) task. The experimental results on four publicly available datasets demonstrate that Y-Net with the edge-aware layers is superior to other state-of-the-art fusion networks in terms of qualitative and quantitative comparison.

# Summary. An optional shortened abstract.
# summary: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.

tags:
- Source Themes
featured: false

links:
url_pdf: 'https://link.springer.com/article/10.1007/s11263-023-01806-w'
# - name: Custom Link
#   url: http://example.org

# url_code: 'https://github.com/HugoBlox/hugo-blox-builder'
# url_dataset: '#'
# url_poster: '#'
# url_project: ''
# url_slides: ''
# url_source: '#'
# url_video: '#'

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  # caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/s9CC2SKySJM)'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
# projects:
# - internal-project

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

<!-- {{% callout note %}}
Create your slides in Markdown - click the *Slides* button to check out the example.
{{% /callout %}} -->

**cite** 
```
@article{64d645a13fda6d7f0631eae6,	author={Zeyu Wang and Xiongfei Li and Libo Zhao and Haoran Duan and Shidong Wang and Hao Liu and Xiaoli Zhang},	pages={2529-2552},	title={When Multi-Focus Image Fusion Networks Meet Traditional Edge-Preservation Technology},	volume=131,	year=2023,}
```


<!-- Add the publication's **full text** or **supplementary notes** here. You can use rich formatting such as including [code, math, and images](https://docs.hugoblox.com/content/writing-markdown-latex/). -->
